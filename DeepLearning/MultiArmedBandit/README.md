# MAB

The Multi-Armed Bandit (MAB) problem, a cornerstone in the study of decision-making under uncertainty, presents a scenario akin to a gambler choosing from multiple slot machines, each with unknown payout rates. This dilemma encapsulates the critical challenge of balancing exploration and exploitation. Rooted in probability and statistics, MAB problems have far-reaching implications in various domains, from optimizing online algorithms to guiding strategic choices in business and healthcare, where decision-makers must continually adapt to evolving environments with incomplete information.

## Overview

This research presents a detailed empirical analysis of Frequentist and Bayesian strategies in addressing the Stochastic Multi-Armed Bandit problem, with a particular focus on the mathematical intricacies involved in decision-making under uncertainty. By employing advanced mathematical models and simulations across diverse scenarios, the study offers profound insights into the performance and applicability of these algorithms. We demonstrate how different strategies fare in terms of reward maximization, best-arm identification, and computational efficiency, offering a comprehensive understanding of the exploration-exploitation trade-off.

## Applications

The study highlights the practical applications of these approaches in fields like online advertising, economics, and healthcare. It offers a detailed comparison, guiding future research in optimizing decision-making algorithms for real-world problems.

```
Code and Results are shown in main.ipynb
```
